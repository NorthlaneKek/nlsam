#!/usr/bin/env python

from __future__ import division, print_function

# Has to be called before importing numpy
from nlsam.multiprocess import multiprocessing_hanging_workaround
multiprocessing_hanging_workaround()

import os
import argparse
import logging
from multiprocessing import cpu_count, freeze_support
from ast import literal_eval

import nibabel as nib
import numpy as np

from nlsam.denoiser import nlsam_denoise
from nlsam.smoothing import local_standard_deviation, sh_smooth, local_piesno
from nlsam.bias_correction import stabilization, corrected_sigma

from dipy.io.gradients import read_bvals_bvecs
from dipy.core.gradients import gradient_table
from dipy.denoise.noise_estimate import piesno


DESCRIPTION = """
Main script for the NLSAM denoising [1], including the bias correction framework from [2].
"""

EPILOG = """
References :

[1] St-Jean, S., Coupe, P., & Descoteaux, M. (2016).
Non Local Spatial and Angular Matching : Enabling higher spatial resolution diffusion MRI datasets through adaptive denoising.
Medical Image Analysis, 32(2016), 115-130.

[2] Koay CG, Ozarslan E and Basser PJ.
A signal transformational framework for breaking the noise floor and its applications in MRI.
Journal of Magnetic Resonance 2009; 197: 108-119.
"""


def buildArgsParser():

    p = argparse.ArgumentParser(description=DESCRIPTION,
                                epilog=EPILOG,
                                add_help=False,
                                formatter_class=argparse.RawTextHelpFormatter)

    #####################
    # Required arguments
    #####################

    required = p.add_argument_group('Required arguments')

    required.add_argument('input', metavar='input',
                          help='Path of the image file to denoise.')

    required.add_argument('output', metavar='output',
                          help='Path for the saved denoised file.')

    required.add_argument('N', metavar='N', type=int,
                          help='Number of receiver coils of the scanner. \n'
                          'Use N=1 in the case of a SENSE (GE, Philips) reconstruction and '
                          'N >= 1 for GRAPPA reconstruction (Siemens).')

    required.add_argument('bvals', metavar='bvals',
                          help='Path of the bvals file, in FSL format.')

    required.add_argument('bvecs', metavar='bvecs',
                          help='Path of the bvecs file, in FSL format.')

    required.add_argument('angular_block_size', metavar='n_angular_neighbors',
                          type=int, help='Number of angular neighbors used for denoising.')

    #####################
    # Optional arguments
    #####################

    optionals = p.add_argument_group('Optional arguments')

    optionals.add_argument('-m', '--mask', metavar='file',
                           help='Path to a binary mask. Only the data inside the mask will be reconstructed.')

    optionals.add_argument('--b0_threshold', metavar='int', default=10, type=int,
                           help='Lowest b-value to be considered as a b0. Default 10.')

    optionals.add_argument('--split_b0s', action='store_true',
                           help='If set and multiple b0s are present, they are split amongst the '
                           'training data.')

    optionals.add_argument('--split_shell', action='store_true',
                           help='If set, each shell is processed by itself.')

    optionals.add_argument('--block_size', dest='spatial_block_size',
                           metavar='tuple', type=literal_eval, default=(3, 3, 3),
                           help='Size of the 3D spatial patch to be denoised. Default : 3, 3, 3')

    optionals.add_argument('--fix_implausible', action='store_true', dest='implausible_signal_fix',
                           help='If set, remove physically implausible signals from the input data by setting '
                           'the b0 signal as the highest value along volumes.\nUseful if your data '
                           'is highly noisy and the S0 signal is low.')

    optionals.add_argument('--is_symmetric', action='store_true',
                           help='If supplied, assumes the set of bvals/bvecs to be already symmetrized,\n'
                           'i.e. All points (x,y,z) on the sphere and (-x,-y,-z) were acquired, such as in full grid DSI.')

    optionals.add_argument('--iterations', metavar='int', default=10, type=int,
                           help='Maximum number of iterations for the l1 reweighting. Default 10.')

    optionals.add_argument('--no_subsample', action='store_false',
                           help='If set, process all the dwis multiple times, '
                           'but note that this option lengthen the total time.\n'
                           'The default is to find the smallest subset so that each dwi is '
                           'processed at least once.')

    g1 = optionals.add_mutually_exclusive_group()

    g1.add_argument('--sh_order', metavar='int', default=8, type=int, choices=[0, 2, 4, 6, 8],
                    help='Spherical harmonics order used for sh_smooth.\n'
                    'Use 0 to disable the spherical harmonics fitting. Default 8')

    g1.add_argument('--load_mhat', metavar='file',
                    help='Load this volume as a m_hat value estimation for the stabilization.\n'
                    'This is used to replace the argument --sh_order with another initialisation for the algorithm.')

    g = optionals.add_mutually_exclusive_group()

    g.add_argument('--noise_est', dest='noise_method',
                   metavar='string', default='piesno',
                   choices=['local_std', 'piesno'],
                   help='Noise estimation method used for estimating sigma.\n'
                   'local_std : Compute local noise standard deviation '
                   'with correction factor. No a priori needed.\n'
                   'piesno (default): Use PIESNO estimation, assumes the presence of '
                   'background in the data.')

    g.add_argument('--load_sigma', metavar='file',
                   help='Load this file as the standard deviation volume.\n'
                   'Will be squared internally to turn into variance.')

    #####################
    # Advanced arguments
    #####################

    advanced = p.add_argument_group('Advanced noise estimation')

    advanced.add_argument('--noise_maps', metavar='file',
                          help='Path of the noise map(s) volume for local piesno.\n'
                          'Either supply a 3D noise map or a stack of 3D maps as a 4D volume.\n'
                          'This is intended for noise maps collected by the scanner (so that there is no signal in those measurements)\n'
                          'which are properly scaled with the rest of the data you collected.\n'
                          'If in doubt, it is safer to use another estimation method with --noise_est')

    advanced.add_argument('--noise_mask', dest='save_piesno_mask', metavar='file',
                          help='If supplied, output filename for saving the mask of noisy voxels found by PIESNO.')

    advanced.add_argument('--save_stab', metavar='file',
                          help='Path to save the intermediate noisy bias corrected volume.')

    advanced.add_argument('--save_sigma', metavar='file',
                          help='Path to save the intermediate standard deviation volume.')

    advanced.add_argument('--save_difference', metavar='file',
                          help='Path to save the absolute difference volume, abs(noisy - denoised).')

    advanced.add_argument('--save_eta', metavar='file',
                          help='Path to save the intermediate underlying signal intensity eta volume.')

    advanced.add_argument('--no_clip_eta', action='store_false',
                          help='If set, allows eta to take negative values during stabilization.')

    ############
    # The rest
    ############

    misc = p.add_argument_group('Logging and multicores options')

    misc.add_argument('--no_stabilization', action='store_true',
                      help='If set, does not correct the data for the noise non gaussian bias.\n'
                      'Useful if your data is already bias corrected or you would like to do it afterwards.')

    misc.add_argument('--no_denoising', action='store_true',
                      help='If set, does not run the nlsam denoising.\n'
                      'Useful if you only want to bias correct your data or get the noise estimation maps only.')

    misc.add_argument('--cores', metavar='int', type=int,
                      help='Number of cores to use for multithreading.')

    misc.add_argument('--use_threading', action='store_true',
                      help='If set, rely on your blas/lapack/spams multithreading capabilities instead of python multiprocessing.\n'
                      'This mode uses less ram, but is slower than multiprocessing and should only be used for very large datasets\n'
                      'or in cases where the amount of available ram is limited.')

    misc.add_argument('--use_f32', action='store_true',
                      help='If supplied, use float32 for inner computations. This option lowers ram usage, but\n'
                      'could lead to numerical precision issues, so use carefully and inspect the final output.')

    misc.add_argument('--mp_method', metavar='string',
                      help='Dispatch method for multiprocessing, see\n'
                      'https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods for more information.\n'
                      'Default : None, use the default, platform dependent method to run multiprocessing.\n'
                      'Only available in python 3.4 and later.')

    misc.add_argument('-f', '--force', action='store_true', dest='overwrite',
                      help='If set, the output denoised volume will be overwritten '
                      'if it already exists.')

    misc.add_argument('-v', '--verbose', action='store_true',
                      help='If set, print useful information message during processing.')

    misc.add_argument('-l', '--log', dest='logfile', metavar='file',
                      help='Save the logging output to this file. Implies verbose output.')

    misc.add_argument("-h", "--help", action="help", help="Show this help message and exit.")

    return p


def main():
    parser = buildArgsParser()
    args = parser.parse_args()

    noise_method = args.noise_method
    sh_order = args.sh_order
    N = args.N

    subsample = args.no_subsample
    is_symmetric = args.is_symmetric
    n_iter = args.iterations
    b0_threshold = args.b0_threshold
    split_b0s = args.split_b0s
    split_shell = args.split_shell
    mp_method = args.mp_method
    use_threading = args.use_threading
    block_size = np.array(args.spatial_block_size + (args.angular_block_size,))
    clip_eta = args.no_clip_eta
    logger = logging.getLogger('nlsam')

    if args.logfile is not None:
        handler = logging.FileHandler(args.logfile)
        args.verbose = True
    else:
        handler = logging.StreamHandler(args.logfile)

    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', "%Y-%m-%d %H:%M:%S")
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    if args.verbose:
        logger.setLevel(logging.INFO)
        logger.info('Verbosity is on')

    if args.no_stabilization:
        logger.info('Stabilization disabled!')

    if args.no_denoising:
        logger.info('Denoising disabled!')

    if args.use_f32:
        logger.info('Computations will be made using float32!')
        dtype = np.float32
    else:
        dtype = np.float64

    if args.use_threading:
        logger.info('Using multithreading instead of multiprocessing, please make sure your blas/lapack/spams '
                    'libraries are built with multithreading support!')

    ##########################################
    #  Load up data and do some sanity checks
    ##########################################

    overwritable_files = [args.output,
                          args.save_sigma,
                          args.save_difference,
                          args.save_eta,
                          args.save_piesno_mask,
                          args.save_stab]

    for f in overwritable_files:
        if f is not None and os.path.isfile(f):
            if args.overwrite:
                logger.warning('Overwriting {}'.format(os.path.realpath(f)))
            else:
                parser.error('{} already exists! Use -f or --force to overwrite it.'.format(f))

    vol = nib.load(args.input)
    data = np.asarray(vol.get_data(caching='unchanged'), dtype=np.float32)
    affine = vol.affine
    header = vol.header
    header.set_data_dtype(np.float32)
    logger.info("Loading data {}".format(os.path.realpath(args.input)))

    if args.mask is not None:
        mask = np.asarray(nib.load(args.mask).get_data(caching='unchanged'), dtype=np.bool)
        logger.info("Loading mask {}".format(os.path.realpath(args.mask)))
    else:
        mask = np.ones(data.shape[:-1], dtype=np.bool)

    bvals, bvecs = read_bvals_bvecs(args.bvals, args.bvecs)
    gtab = gradient_table(bvals, bvecs, b0_threshold=b0_threshold)

    if args.implausible_signal_fix:
        data[..., gtab.b0s_mask] = np.max(data, axis=-1, keepdims=True)
        logger.info("Fixing b0 implausible signals to max(dwi) voxelwise")

    if args.cores is None or args.cores > cpu_count():
        n_cores = cpu_count()
    else:
        n_cores = args.cores

    if len(block_size) != len(data.shape):
        raise ValueError('Block shape {} and data shape {} are not of the same '
                         'length'.format(block_size, data.shape))

    if data.shape[:-1] != mask.shape:
        raise ValueError('data shape is {}, but mask shape {} is different!'.format(data.shape, mask.shape))

    #########################
    #  Noise estimation part
    #########################

    if args.load_sigma is not None:
        sigma = np.asarray(nib.load(args.load_sigma).get_data(caching='unchanged'), dtype=np.float32)
        logger.info("Loading sigma {}".format(os.path.realpath(args.load_sigma)))

        # If we have a bunch of 4D views, we only want a 3D array
        if sigma.ndim == data.ndim:
            sigma = np.median(sigma, axis=-1)
            logger.warning("{} was {}D, but was downcasted to {}D.".format(os.path.realpath(args.load_sigma), sigma.ndim + 1, sigma.ndim))

        if data.shape[:-1] != sigma.shape:
            raise ValueError('data shape is {}, but sigma shape {} is different!'.format(data.shape, sigma.shape))

    elif args.noise_maps is not None:
        noise_maps = np.asarray(nib.load(args.noise_maps).get_data(caching='unchanged'), dtype=np.float32)
        logger.info("Loading {} as a noise map".format(os.path.realpath(args.noise_maps)))

        # Local piesno works on 4D, so we need to broadcast before
        if noise_maps.ndim == 3:
            noise_maps = noise_maps[..., None]

        sigma, mask_noise = local_piesno(noise_maps, N=N, return_mask=True)

        if args.save_piesno_mask is not None:
            nib.save(nib.Nifti1Image(mask_noise.astype(np.int16), affine), args.save_piesno_mask)
            logger.info("Piesno mask saved as {}".format(os.path.realpath(args.save_piesno_mask)))

    elif noise_method == 'piesno':
        logger.info("Estimating noise with method {}".format(noise_method))
        sigma_1D, mask_noise = piesno(data, N=N, return_mask=True)
        sigma = np.broadcast_to(sigma_1D[None, None, :, None], data.shape)

        if args.save_piesno_mask is not None:
            nib.save(nib.Nifti1Image(mask_noise.astype(np.int16), affine), args.save_piesno_mask)
            logger.info("Piesno mask saved as {}".format(os.path.realpath(args.save_piesno_mask)))

        # If the detected noise standard deviation is low and the noise mask has few voxels,
        # maybe something went wrong. We check here that at least 1% of noisy voxels
        # were found and warn the user otherwise.
        frac_noisy_voxels = np.sum(mask_noise) / np.size(mask_noise) * 100

        if frac_noisy_voxels < 1.:
            logger.warning('PIESNO was used with N={}, but it found only {:.3f}%'
                           ' of voxels as pure noise with a mean standard deviation'
                           ' of {:.5f}. This is suspicious, so please check'
                           ' the resulting sigma volume if something went wrong.'
                           ' In cases where PIESNO is not working, you might want to try'
                           ' --noise_est local_std'.format(N, frac_noisy_voxels, np.mean(sigma_1D)))

    elif noise_method == 'local_std':
        logger.info("Estimating noise with method {}".format(noise_method))
        sigma = local_standard_deviation(data, n_cores=n_cores, mp_method=mp_method)

        # Compute the corrected value for each 3D volume
        if N > 0:
            sigma = corrected_sigma(data, sigma, N, mask=mask)

    if args.save_sigma is not None:
        nib.save(nib.Nifti1Image(sigma, affine), args.save_sigma)
        logger.info("Sigma map saved as {}".format(os.path.realpath(args.save_sigma)))

    ##################
    #  Stabilizer part
    ##################

    if args.no_stabilization:
        data_stabilized = data
    else:
        logger.info("Now performing stabilization")

        # load m_hat if we supplied the argument
        if args.load_mhat is not None:
            m_hat = np.asarray(nib.load(args.load_mhat).get_data(caching='unchanged'), dtype=np.float32)
            logger.info("Loading m_hat {}".format(os.path.realpath(args.load_mhat)))
            if m_hat.shape != data.shape:
                raise ValueError('m_hat shape {} is different from data shape {}!'.format(m_hat.shape, data.shape))
        else:
            # sh_order 0 or negative just feeds the data as is without a sh fit smoothing
            if sh_order <= 0:
                m_hat = data
            else:
                logger.info("Estimating m_hat with sh order {}".format(sh_order))

                # Raise warning for sh order if there is not enough DWIs
                required_dwis = int((sh_order + 1) * (sh_order + 2) / 2)
                number_of_dwis = data.shape[-1] - np.sum(gtab.b0s_mask)
                if number_of_dwis < required_dwis:
                    logger.warning('We recommend having at least {} unique DWIs volumes, '
                                   'but you currently have {} volumes. Try lowering the '
                                   'parameter --sh_order in case of non '
                                   'convergence.'.format(required_dwis, number_of_dwis))

                m_hat = sh_smooth(data, gtab, sh_order=sh_order).clip(min=0)

        data_stabilized, eta = stabilization(data, m_hat, sigma, N,
                                             mask=mask,
                                             clip_eta=clip_eta,
                                             return_eta=True,
                                             n_cores=n_cores,
                                             mp_method=mp_method,)

        if args.save_eta is not None:
            nib.save(nib.Nifti1Image(eta, affine), args.save_eta)
            logger.info("eta volume saved as {}".format(os.path.realpath(args.save_eta)))

        if args.save_stab is not None:
            nib.save(nib.Nifti1Image(data_stabilized, affine), args.save_stab)
            logger.info("Stabilized data saved as {}".format(os.path.realpath(args.save_stab)))

        del m_hat, eta

    ##################
    #  Denoising part
    ##################

    if not args.no_denoising:
        logger.info("Now denoising ".format(os.path.realpath(args.input)))

        # If we have a bunch of 4D views, we only want a 3D array
        if sigma.ndim == data.ndim:
            sigma = np.median(sigma, axis=-1)
        del data

        data_denoised = nlsam_denoise(data_stabilized, sigma, bvals, bvecs, block_size,
                                      mask=mask,
                                      is_symmetric=is_symmetric,
                                      n_cores=n_cores,
                                      split_b0s=split_b0s,
                                      split_shell=split_shell,
                                      subsample=subsample,
                                      n_iter=n_iter,
                                      b0_threshold=b0_threshold,
                                      dtype=dtype,
                                      use_threading=use_threading,
                                      mp_method=mp_method)

        nib.save(nib.Nifti1Image(data_denoised.astype(np.float32), affine, header), args.output)
        logger.info("Denoised data saved as {}".format(os.path.realpath(args.output)))

        if args.save_difference is not None:
            nib.save(nib.Nifti1Image(np.abs(data_denoised - data).astype(np.float32), affine, header), args.save_difference)
            logger.info("Difference map saved as {}".format(os.path.realpath(args.save_difference)))


if __name__ == "__main__":
    freeze_support()
    main()
